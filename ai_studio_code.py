import os
import math
import json
import csv

def create_file(path, content):
    directory = os.path.dirname(path)
    if directory and not os.path.exists(directory):
        os.makedirs(directory, exist_ok=True)
    with open(path, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"âœ… Created: {path}")

# --- 1. æ ¸å¿ƒ BM25 æ£€ç´¢å¼•æ“ (Python å®ç°) ---
bm25_engine_code = """
import math
import re
import csv
import os

class BM25:
    def __init__(self, corpus, k1=1.5, b=0.75):
        self.corpus = corpus
        self.k1 = k1
        self.b = b
        self.doc_len = [len(doc) for doc in corpus]
        self.avgdl = sum(self.doc_len) / len(corpus)
        self.n = len(corpus)
        self.tf = []
        self.df = {}
        self.idf = {}
        self._initialize()

    def _initialize(self):
        for doc in self.corpus:
            tmp_tf = {}
            for word in doc:
                tmp_tf[word] = tmp_tf.get(word, 0) + 1
            self.tf.append(tmp_tf)
            for word in tmp_tf.keys():
                self.df[word] = self.df.get(word, 0) + 1
        for word, freq in self.df.items():
            self.idf[word] = math.log((self.n - freq + 0.5) / (freq + 0.5) + 1)

    def get_score(self, query, index):
        score = 0
        doc_tf = self.tf[index]
        for word in query:
            if word not in doc_tf: continue
            score += (self.idf[word] * doc_tf[word] * (self.k1 + 1) / 
                      (doc_tf[word] + self.k1 * (1 - self.b + self.b * self.doc_len[index] / self.avgdl)))
        return score

def tokenize(text):
    return re.findall(r'\\w+', text.lower())

def load_data(data_dir):
    documents = []
    metadata = []
    for filename in os.listdir(data_dir):
        if filename.endswith('.csv'):
            with open(os.path.join(data_dir, filename), 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    content = " ".join(row.values())
                    documents.append(tokenize(content))
                    metadata.append({"source": filename, "data": row})
    return documents, metadata

def search(query_str):
    data_dir = os.path.join(os.path.dirname(__file__), "../data")
    docs, meta = load_data(data_dir)
    bm25 = BM25(docs)
    query = tokenize(query_str)
    scores = [(bm25.get_score(query, i), i) for i in range(len(docs))]
    scores.sort(key=lambda x: x[0], reverse=True)
    
    results = []
    for score, index in scores[:5]: # è¿”å›å‰5ä¸ªæœ€ç›¸å…³çš„è§„èŒƒ
        if score > 0:
            item = meta[index]
            results.append(f"[Score: {score:.2f}] Source: {item['source']}\\nContent: {item['data']}\\n")
    return "\\n".join(results) if results else "No matching guidelines found."

if __name__ == "__main__":
    import sys
    query = sys.argv[1] if len(sys.argv) > 1 else ""
    print(search(query))
"""

# --- 2. æ›´åŠ å®Œæ•´çš„è§„èŒƒæ•°æ® ---

# UX äº¤äº’çº¢çº¿
ux_guidelines = """Scenario,Rule,Priority,Detail
Validation,è¡¨å•æ ¡éªŒå¿…é¡»åœ¨å¤±ç„¦(Blur)æ—¶è§¦å‘,High,å‡å°‘ç”¨æˆ·è¾“å…¥æ—¶çš„å¹²æ‰°
Navigation,é¢åŒ…å±‘å¯¼èˆªå¿…é¡»åŒ…å«å½“å‰é¡µé¢çš„çˆ¶çº§è·¯å¾„,Medium,ç¡®ä¿ç”¨æˆ·çŸ¥é“è‡ªå·±åœ¨å“ªé‡Œ
Feedback,è¶…è¿‡2ç§’çš„æ“ä½œå¿…é¡»æ˜¾ç¤ºè¿›åº¦æ¡è€Œéé™æ­¢Loading,Critical,ç¼“è§£ç”¨æˆ·ç„¦è™‘
Buttons,å…³é”®åˆ é™¤æ“ä½œå¿…é¡»ä½¿ç”¨çº¢è‰²ä¸»é¢˜å¹¶å¸¦æœ‰äºŒæ¬¡ç¡®è®¤,High,é˜²æ­¢è¯¯åˆ 
"""

# å­—ä½“ä¸æ’ç‰ˆ
typography = """Token,FontFamily,Size,Weight,Usage
--font-h1,PingFang SC / Inter,32px,600,ä¸€çº§æ ‡é¢˜
--font-body,PingFang SC / Inter,14px,400,æ­£æ–‡å†…å®¹
--font-code,JetBrains Mono,12px,400,ä»£ç å—/æŠ€æœ¯æŒ‡æ ‡
"""

# è®¾è®¡ç³»ç»Ÿæ ¸å¿ƒç»„ä»¶æ˜ å°„
components = """Component,Internal_Tag,Library,Status,Usage_Notes
Table,n-data-table,Nexus-UI,Ready,å¿…é¡»é…ç½® row-key å’Œ virtual-scroll
Button,n-button,Nexus-UI,Ready,ä¸»æŒ‰é’®å…¨å±€åªèƒ½å‡ºç°ä¸€ä¸ª
Modal,n-modal,Nexus-UI,Ready,å®½åº¦å»ºè®®å›ºå®šä¸º 520px/840px/1200px
"""

# å“ç‰Œé¢œè‰²
brand = """Category,Token,Value,Usage
Brand,Primary,#0052D9,ä¸»è¦æ“ä½œ/é“¾æ¥
Status,Success,#2BA471,æˆåŠŸ/åœ¨çº¿
Status,Error,#D54941,æŠ¥é”™/ç¦»çº¿
Neutral,Border,#DCDCDC,è¾¹æ¡†é¢œè‰²
"""

# --- 3. ç”Ÿæˆ Skill è¯´æ˜ä¹¦ ---
skill_main = """# Enterprise UI/UX Engineering (BM25 Enabled)

ä½ æ˜¯ä¸€ä¸ªé›†æˆäº† **BM25 è¯­ä¹‰æ£€ç´¢** çš„ä¼ä¸šçº§ UI/UX ä¸“å®¶ AIã€‚

## æ£€ç´¢æœºåˆ¶
ä½ æ‹¥æœ‰ä¸€ä¸ªåŸºäº BM25 ç®—æ³•çš„æ£€ç´¢å·¥å…· `search_engine.py`ã€‚
å½“ç”¨æˆ·è¦æ±‚è®¾è®¡é¡µé¢æˆ–ç¼–å†™ UI ä»£ç æ—¶ï¼Œä½ **å¿…é¡»**ï¼š
1. å…ˆæå–ç”¨æˆ·éœ€æ±‚ä¸­çš„å…³é”®è¯ï¼ˆå¦‚ï¼šè¡¨æ ¼ã€æŠ¥é”™ã€ä¸»è‰²è°ƒï¼‰ã€‚
2. è°ƒç”¨ `python3 .shared/enterprise-ui-skill/scripts/search_engine.py "<å…³é”®è¯>"`ã€‚
3. æ ¹æ®è¿”å›çš„ç›¸å…³æ€§è¯„åˆ†ï¼ˆScoreï¼‰æœ€é«˜çš„è§„èŒƒæ¥ç”Ÿæˆä»£ç ã€‚

## æ ¸å¿ƒè®¾è®¡å“²å­¦
- **Token First**: ä¸¥ç¦ç›´æ¥å†™ `color: #0052D9`ï¼Œå¿…é¡»æ£€ç´¢å¯¹åº”çš„ Token å¦‚ `var(--brand-primary)`ã€‚
- **UX Consistency**: ä¸¥æ ¼éµå®ˆ `ux-guidelines.csv` ä¸­çš„åé¦ˆä¸æ ¡éªŒæœºåˆ¶ã€‚
- **Library Compliance**: ä»…ä½¿ç”¨å†…éƒ¨ `Nexus-UI` ç»„ä»¶ã€‚
"""

def main():
    root = ".shared/enterprise-ui-skill"
    # åˆ›å»ºç›®å½•å’Œæ–‡ä»¶
    create_file(f"{root}/data/ux_guidelines.csv", ux_guidelines)
    create_file(f"{root}/data/typography.csv", typography)
    create_file(f"{root}/data/components.csv", components)
    create_file(f"{root}/data/brand.csv", brand)
    
    create_file(f"{root}/scripts/search_engine.py", bm25_engine_code)
    create_file(f"{root}/skill-main.md", skill_main)
    
    # Cursor è§„åˆ™é…ç½®
    cursor_rules = {
        "name": "Enterprise UI/UX Specialist",
        "instruction": f"Always query the BM25 search engine in {root}/scripts/search_engine.py before providing UI/UX solutions to ensure alignment with corporate standards."
    }
    create_file(".cursorrules", json.dumps(cursor_rules, indent=2))

    print("\nğŸš€ [é«˜çº§ç‰ˆ] ä¼ä¸š UI/UX Skill å·²ç”Ÿæˆï¼Œé›†æˆ BM25 æ£€ç´¢ç®—æ³•ï¼")

if __name__ == "__main__":
    main()
